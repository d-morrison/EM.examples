---
title: "McLachlan-p-17"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{McLachlan-p-17}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


```{r setup}
library(EM.examples)
library(ggplot2)
library(dplyr)
library(pander)
```

Example from McLachlan & Krishnan:

```{r}
rm(list = ls())
n = 50
mu = c(0,2)
sigma = 1
pi = c(.8,.2)
set.seed(1)
Z = rbinom(n = n, size = 1, p = pi[2]) |> factor(labels = c("Z = 0", "Z = 1"))
Y = rnorm(n = n, mean = ifelse(Z == "Z = 0", mu[1], mu[2]), sd = sigma)
hist(Y, breaks = 10)
data1 = tibble(Z, Y)

```

Here's the observed data:

```{r}
ggplot(data1, aes(x = Y)) +
  geom_histogram() +
  theme(axis.text=element_text(size=14),
        axis.title=element_text(size=18,face="bold"))

```

And here's the (latent) complete data:

```{r}
ggplot(data1, aes(x = Y)) +
  geom_histogram() +
  facet_wrap(~Z, ncol = 1) +
  theme(
    strip.text.x = element_text(size = 18),
    axis.text=element_text(size=14),
        axis.title=element_text(size=18,face="bold"))

```

```{r,fig.height=6}

`p(Y=y|Z=1)` = dnorm(Y, mu[1], sd = sigma)
`p(Y=y|Z=2)` = dnorm(Y, mu[2], sd = sigma)

likelihood = function(pi1)
{
  sapply(pi1, 
    function(x)
    {
      (x * `p(Y=y|Z=1)` + (1 - x) * `p(Y=y|Z=2)`) |> prod()
    })
  
}

loglik = function(pi1) log(likelihood(pi1))

par(mfrow = c(2,1))
plot(likelihood, xlim = c(0,1), xlab = "pi_1")
plot(loglik, xlim = c(0,1), xlab = "pi_1", ylab = "log(likelihood)")
```

# EM Algorithm

```{r, fig.height = 6, fig.width = 6}

`p(Z=1)`  = .5 # initial guess
diff = Inf
tolerance = .00001
progress = tibble(
  Iteration = 0,
  `p(Z=1)` = `p(Z=1)`,
  loglik =  loglik(`p(Z=1)`)
)
max_iterations = 1000

par(mfrow = c(1,1))
  
plot(loglik, xlim = c(0,1), xlab = "p(Z=0)", ylab = "log(likelihood)", lwd = 2)
  
for(i in 1:max_iterations)
{
  `p(Y=y,Z=1)` = `p(Y=y|Z=1)`*`p(Z=1)`
  `p(Y=y,Z=2)` = `p(Y=y|Z=2)`*(1 - `p(Z=1)`)
  `p(Y=y)` = `p(Y=y,Z=1)` + `p(Y=y,Z=2)`
  `p(Z=1|Y=y)` = `p(Y=y,Z=1)`/`p(Y=y)`
  `p(Z=2|Y=y)` = `p(Y=y,Z=2)`/`p(Y=y)`
  `pi-hat-prev` = `p(Z=1)`
  `p(Z=1)` = mean(`p(Z=1|Y=y)`)
  
  Q = function(pi1)
  {
    sapply(pi1, 
      FUN = function(x)
        {
           sum((log(`p(Y=y|Z=1)`) + log(x))*`p(Z=1|Y=y)` +
               (log(`p(Y=y|Z=2)`) + log(1-x))*`p(Z=2|Y=y)`)
        })
  }
  
  # plot(loglik, xlim = c(0,1), xlab = "p(Z=0)", ylab = "log(likelihood)", lwd = 2)
  points(x = `pi-hat-prev`, y = loglik(`pi-hat-prev`), col = "red", pch = 16)
  plot(Q, add = TRUE, col = 'blue', lwd = 2)
  legend(x = "topleft", col = c('black', 'blue'), lty = 1, 
    lwd = 2,
    legend = c("log-likelihood", expression(Q(pi,hat(pi)))))
  points(x = `p(Z=1)`, y = loglik(`p(Z=1)`), pch = 16, col = 'orange')
  points(x = `p(Z=1)`, y = Q(`p(Z=1)`), col = "green", pch = 16)
  
  
  
  diff = `p(Z=1)` - `pi-hat-prev`
  new_results = tibble(
    Iteration = i,
    `p(Z=1)` = `p(Z=1)`,
    loglik = loglik(`p(Z=1)`),
    `diff(loglik)` = diff)
  
  progress = 
    bind_rows(progress, new_results)
    
  if(diff < tolerance) break;  
}

pander(progress)


```


