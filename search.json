[{"path":"https://d-morrison.github.io/EM.examples/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2022 EM.examples authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://d-morrison.github.io/EM.examples/articles/McLachlan-p-17.html","id":"em-algorithm","dir":"Articles","previous_headings":"","what":"EM Algorithm","title":"McLachlan-p-17","text":"","code":"`p(Z=0)`  = .5 # initial guess for `pi-hat` diff = Inf tolerance = .00001 progress = tibble(   Iteration = 0,   `p(Z=0)` = `p(Z=0)`,   loglik =  loglik(`p(Z=0)`) ) max_iterations = 1000  par(mfrow = c(1,1))  plot(loglik, xlim = c(0,1), xlab = \"p(Z=0)\", ylab = \"log(likelihood)\", lwd = 2)  for(i in 1:max_iterations) {   # E step:   Estep = tibble(     Y, # observed data     `p(Y=y|Z=0)`,     `p(Y=y|Z=1)`,     `p(Y=y,Z=0)` = `p(Y=y|Z=0)`*`p(Z=0)`, # `p(Z=0)` = \"pi-hat\"     `p(Y=y,Z=1)` = `p(Y=y|Z=1)`*(1 - `p(Z=0)`),     `p(Y=y)` = `p(Y=y,Z=0)` + `p(Y=y,Z=1)`,     `p(Z=0|Y=y)` = `p(Y=y,Z=0)`/`p(Y=y)`,     `p(Z=1|Y=y)` = 1 - `p(Z=0|Y=y)` # == `p(Y=y,Z=1)`/`p(Y=y)`)   )      # M step   `pi-hat-prev` = `p(Z=0)` # save the previous pi-hat estimate so we can graph our progress   `p(Z=0)` = mean(Estep$`p(Z=0|Y=y)`) # here's the new pi-hat estimate      Q = function(pi1)   {     sapply(pi1,        FUN = function(x)       {         with(Estep, sum((log(`p(Y=y|Z=0)`) + log(x))*`p(Z=0|Y=y)` +             (log(`p(Y=y|Z=1)`) + log(1-x))*`p(Z=1|Y=y)`))       })   }      # plot(loglik, xlim = c(0,1), xlab = \"p(Z=0)\", ylab = \"log(likelihood)\", lwd = 2)   points(x = `pi-hat-prev`, y = loglik(`pi-hat-prev`), col = \"red\", pch = 16)   plot(Q, add = TRUE, col = 'blue', lwd = 2)   legend(x = \"topleft\", col = c('black', 'blue'), lty = 1,      lwd = 2,     legend = c(\"log-likelihood\", expression(Q(pi,hat(pi)))))   points(x = `p(Z=0)`, y = loglik(`p(Z=0)`), pch = 16, col = 'orange')   points(x = `p(Z=0)`, y = Q(`p(Z=0)`), col = \"green\", pch = 16)            diff = `p(Z=0)` - `pi-hat-prev` # this is wrong; should be diff of logliks   new_results = tibble(     Iteration = i,     `p(Z=0)` = `p(Z=0)`,     loglik = loglik(`p(Z=0)`),     `diff(loglik)` = diff)      progress =      bind_rows(progress, new_results)      if(diff < tolerance) break;   } pander(progress)"},{"path":"https://d-morrison.github.io/EM.examples/articles/mixmodel-benchmark-r.html","id":"problem-summary","dir":"Articles","previous_headings":"","what":"Problem summary","title":"mixmodel-benchmark-r","text":"statistics, finite mixture model probabilistic model observation comes one several latent subpopulations, subpopulation labels observable. example, suppose tying model weights birds local park. birds belong two flocks, flocks different feeding grounds, different distributions weights. However, don’t know birds belong flock catch weighing. like estimate mean weight standard deviation flock, well proportion caught birds come flock. Supposed catch weigh \\(n = 100\\) birds, recorded weights \\(y_1,...y_n\\). Let \\(X_i\\) represent flock bird \\(\\) belongs , \\(X=1\\) representing one flock \\(X=2\\) representing flock. mixture model data structure: \\[p(Y=y) = \\sum_{x\\\\{1,2\\}} p(Y=y|X=x)P(X=x)\\] 1 complete model, let’s assume \\(p(Y=y|X=1)\\) Gaussian (“bell-curve”) distribution parameters \\(\\mu_1\\) \\(\\sigma_1\\), similarly p(Y=y|X=2)$. want estimate five parameters: \\(\\mu_1 := \\text{E}[Y|X=1]\\): average weight birds flock 1 \\(\\sigma_1 := \\text{SD}(Y|X=1)\\): standard deviation weights among birds flock 1 \\(\\mu_2 := \\text{E}[Y|X=2]\\): average weight birds flock 2 \\(\\sigma_2 := \\text{SD}(Y|X=2)\\): standard deviation weights among birds flock 2 \\(\\pi_1 := P(X=1)\\): proportion caught birds belong flock 12 directly observe flock membership weighed bird, \\(x_1,...,x_n\\), count number tbat came flock, \\(n_1\\) \\(n_2\\). easy problem: \\(\\hat{\\mu}_1 = \\sum_{\\{: x_i = 1\\}} Y_i\\) \\(\\hat{\\sigma}_1 = \\sqrt{\\frac{1}{n_1} \\sum_{\\{: x_i = 1\\}}(Y_i - \\hat{\\mu}_1)^2}\\) \\(\\hat{\\pi_1} = n_1/n\\) [similarly \\(\\mu_2\\) \\(\\sigma_2\\)] can’t observe \\(x\\)? Can still estimate \\(\\mu_1\\), \\(\\mu_2\\), \\(\\sigma_1\\), \\(\\sigma_2\\), \\(\\pi\\)? try directly maximize likelihood observed data, \\(\\mathcal{L} = \\prod_{\\1:n} {p(Y=y_i)}\\), taking derivative log-likelihood \\(\\ell = \\log{\\mathcal{L}}\\), setting ’ equal zero, solving parameters, quickly run difficulties taking derivative \\(\\ell\\), \\(p(Y=y_i)\\) sum (try !).","code":""},{"path":"https://d-morrison.github.io/EM.examples/articles/mixmodel-benchmark-r.html","id":"em-algorithm-to-the-rescue","dir":"Articles","previous_headings":"","what":"EM algorithm to the rescue","title":"mixmodel-benchmark-r","text":"EM algorithm iterative method finding maximum likelihood estimates parameters models latent (unobserved) variables. Gaussian mixture model code assumes observed data, \\(Y\\), generated either one two Gaussian distributions means \\(\\mu_1\\) \\(mu_2\\) common standard deviation \\(\\sigma\\). probability data coming first Gaussian distribution \\(\\pi\\), probability data coming second Gaussian distribution \\(1 - \\pi\\). gen_data() function generates data according Gaussian mixture model, fit_model() function performs EM algorithm. E_step function calculates expected value log-likelihood given current estimates parameters observed data, M_step updates estimates parameters based expected log-likelihood. algorithm continues iterate difference log-likelihood consecutive iterations less specified tolerance (tolerance). results algorithm saved progress tibble shows values estimated parameter pi-hat log-likelihood iteration.","code":"library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(pander)"},{"path":"https://d-morrison.github.io/EM.examples/articles/mixmodel-benchmark-r.html","id":"generate-data","dir":"Articles","previous_headings":"","what":"Generate data","title":"mixmodel-benchmark-r","text":"","code":"gen_data = function(     n = 500000,     mu = c(0,2),     sigma = 1,     pi = 0.8) {      tibble(     Obs.ID = 1:n,     Z = (runif(n) > pi) + 1,     Y = rnorm(n = n, mean = mu[Z], sd = sigma)   ) |>     select(-Z) |>     mutate(       `p(Y=y|Z=1)` = dnorm(Y, mu[1], sd = sigma),       `p(Y=y|Z=2)` = dnorm(Y, mu[2], sd = sigma),     )    } set.seed(1) data = gen_data(n = 500000, pi = 0.8) data |> head(6) |> pander()"},{"path":"https://d-morrison.github.io/EM.examples/articles/mixmodel-benchmark-r.html","id":"fit-model","dir":"Articles","previous_headings":"","what":"Fit model","title":"mixmodel-benchmark-r","text":"","code":"fit_model = function(     data,     `p(Z=1)` = 0.5, # initial guess for `pi-hat`     tolerance = 0.00001,     max_iterations = 1000,     verbose = FALSE ) {      # pre-allocate a table of results by iteration:   progress = tibble(       Iteration = 0:max_iterations,       `p(Z=1)` = NA_real_,       loglik =  NA_real_,       diff_loglik = NA_real_     )      # initial E step, to perform needed calculations for initial likelihood:   data = data |> E_step(`p(Z=1)` = `p(Z=1)`)    ll = loglik(data)   progress[1, ] = list(0, `p(Z=1)`, ll, NA)      for(i in 1:max_iterations)   {     # M step: re-estimate parameters     `p(Z=1)` = data |> M_step()          # E step: re-compute distribution of missing variables, using parameters     data = data |> E_step(`p(Z=1)` = `p(Z=1)`)          # Assess convergence          ## save the previous log-likelihood so we can test for convergence     ll_old = ll          ## here's the new log-likelihood     ll = loglik(data)          ll_diff = ll - ll_old          progress[i+1, ] = list(i, `p(Z=1)`, ll, ll_diff)          if(verbose) print(progress[i+1, ])          if(ll_diff < tolerance) break;   }      return(progress[1:(i+1), ]) }"},{"path":"https://d-morrison.github.io/EM.examples/articles/mixmodel-benchmark-r.html","id":"e-step","dir":"Articles","previous_headings":"Fit model","what":"E step","title":"mixmodel-benchmark-r","text":"","code":"E_step = function(data, `p(Z=1)`) {   data |>     mutate(       `p(Y=y, Z=1)` = `p(Y=y|Z=1)` * `p(Z=1)`,       `p(Y=y, Z=2)` = `p(Y=y|Z=2)` * (1 - `p(Z=1)`),       `p(Y=y)`      = `p(Y=y, Z=1)` + `p(Y=y, Z=2)`,       `p(Z=1|Y=y)`  = `p(Y=y, Z=1)` / `p(Y=y)`,     ) }"},{"path":"https://d-morrison.github.io/EM.examples/articles/mixmodel-benchmark-r.html","id":"m-step","dir":"Articles","previous_headings":"Fit model","what":"M step","title":"mixmodel-benchmark-r","text":"","code":"M_step = function(data) {   data |> pull(`p(Z=1|Y=y)`) |> mean() }"},{"path":"https://d-morrison.github.io/EM.examples/articles/mixmodel-benchmark-r.html","id":"log-likelihood","dir":"Articles","previous_headings":"Fit model","what":"Log-likelihood","title":"mixmodel-benchmark-r","text":"Compute log-likelihood observed data given current parameter estimates:","code":"loglik = function(data) {   data |> pull(`p(Y=y)`) |> log() |> sum() }"},{"path":"https://d-morrison.github.io/EM.examples/articles/mixmodel-benchmark-r.html","id":"results","dir":"Articles","previous_headings":"","what":"Results","title":"mixmodel-benchmark-r","text":"Finally, system.time() function used measure time takes run fit_model() function: ’s happened:","code":"{results = fit_model(data, tolerance = 0.00001)} |>    system.time() #>    user  system elapsed  #>   0.437   0.031   0.468 print(results, n = Inf) #> # A tibble: 19 × 4 #>    Iteration `p(Z=1)`   loglik diff_loglik #>        <int>    <dbl>    <dbl>       <dbl> #>  1         0    0.5   -877590.    NA       #>  2         1    0.665 -837000.     4.06e+4 #>  3         2    0.738 -828034.     8.97e+3 #>  4         3    0.770 -825959.     2.07e+3 #>  5         4    0.785 -825455.     5.05e+2 #>  6         5    0.793 -825328.     1.27e+2 #>  7         6    0.797 -825295.     3.24e+1 #>  8         7    0.799 -825287.     8.36e+0 #>  9         8    0.800 -825285.     2.17e+0 #> 10         9    0.800 -825284.     5.63e-1 #> 11        10    0.800 -825284.     1.46e-1 #> 12        11    0.800 -825284.     3.81e-2 #> 13        12    0.800 -825284.     9.92e-3 #> 14        13    0.801 -825284.     2.58e-3 #> 15        14    0.801 -825284.     6.73e-4 #> 16        15    0.801 -825284.     1.75e-4 #> 17        16    0.801 -825284.     4.56e-5 #> 18        17    0.801 -825284.     1.19e-5 #> 19        18    0.801 -825284.     3.09e-6 library(ggplot2) results |>    ggplot(aes(     x = `p(Z=1)`,     y = loglik,     col = Iteration   )) +    geom_point() +   geom_path(     arrow = arrow(     angle = 20,       type = \"open\"   )) +   theme_bw() +   ylab(\"log-likelihood\") +   theme(     legend.position = \"bottom\"   )"},{"path":"https://d-morrison.github.io/EM.examples/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Douglas Ezra Morrison. Author, maintainer, copyright holder.","code":""},{"path":"https://d-morrison.github.io/EM.examples/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Morrison D (2024). EM.examples: Examples EM Algorithms. R package version 0.0.0.9000,  https://github.com/d-morrison/EM.examples, https://d-morrison.github.io/EM.examples/.","code":"@Manual{,   title = {EM.examples: Examples of EM Algorithms},   author = {Douglas Ezra Morrison},   year = {2024},   note = {R package version 0.0.0.9000,  https://github.com/d-morrison/EM.examples},   url = {https://d-morrison.github.io/EM.examples/}, }"},{"path":"https://d-morrison.github.io/EM.examples/index.html","id":"emexamples","dir":"","previous_headings":"","what":"Examples of EM Algorithms","title":"Examples of EM Algorithms","text":"R package implements examples EM (Expectation-Maximization) algorithms use instruction.","code":""},{"path":"https://d-morrison.github.io/EM.examples/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Examples of EM Algorithms","text":"","code":"library(devtools) install_github(\"d-morrison/EM.examples\")"},{"path":"https://d-morrison.github.io/EM.examples/reference/likelihood_bin_mix.html","id":null,"dir":"Reference","previous_headings":"","what":"Title — likelihood_bin_mix","title":"Title — likelihood_bin_mix","text":"Title","code":""},{"path":"https://d-morrison.github.io/EM.examples/reference/likelihood_bin_mix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Title — likelihood_bin_mix","text":"","code":"likelihood_bin_mix(x, pi, `p(X=1|Z=0)` = 1/2, `p(X=1|Z=1)` = 1/4)"},{"path":"https://d-morrison.github.io/EM.examples/reference/likelihood_bin_mix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Title — likelihood_bin_mix","text":"pi","code":""},{"path":"https://d-morrison.github.io/EM.examples/reference/run_app.html","id":null,"dir":"Reference","previous_headings":"","what":"Run the Shiny Application — run_app","title":"Run the Shiny Application — run_app","text":"Run Shiny Application","code":""},{"path":"https://d-morrison.github.io/EM.examples/reference/run_app.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run the Shiny Application — run_app","text":"","code":"run_app(   onStart = NULL,   options = list(),   enableBookmarking = NULL,   uiPattern = \"/\",   ... )"},{"path":"https://d-morrison.github.io/EM.examples/reference/run_app.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run the Shiny Application — run_app","text":"onStart function called app actually run. needed shinyAppObj, since shinyAppDir case, global.R file can used purpose. options Named options passed runApp call (can following: \"port\", \"launch.browser\", \"host\", \"quiet\", \"display.mode\" \"test.mode\"). can also specify width height parameters provide hint embedding environment ideal height/width app. enableBookmarking Can one \"url\", \"server\", \"disable\". default value, NULL, respect setting previous calls  enableBookmarking(). See enableBookmarking() information bookmarking app. uiPattern regular expression applied GET request determine whether ui used handle request. Note entire request path must match regular expression order match considered successful. ... arguments pass golem_opts. See `?golem::get_golem_options` details.","code":""}]
